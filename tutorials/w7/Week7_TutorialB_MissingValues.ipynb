{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oywaxxFTGg1x"
      },
      "source": [
        "\n",
        "# Tutorial 7b: Data Imputation\n",
        "\n",
        "Marcus Frean\n",
        "\n",
        "*with thanks to Baligh Al-Helali (PhD, VUW, 2021)*\n",
        "\n",
        "This covers:\n",
        "\n",
        "* The deletion approach\n",
        "    - Deleting the incomplete features\n",
        "    - Deleting the incomplete instances\n",
        "\n",
        "* pandas\n",
        "    - Simple imputation using pandas\n",
        "    - Interpolation imputation using pandas\n",
        "    \n",
        "* sklearn\n",
        "    - Simple imputation using sklearn\n",
        "    - KNN-based imputation using skearn\n",
        "    - Iterative imputation using skearn\n",
        "\n",
        "* Applying the learned models to incomplete test data\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kq7u4kOBWz31"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvW3yzD33Fq2"
      },
      "source": [
        "## Loading and exploring the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idmBZgaH_oge"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Or load titanic data that are alraedy split into train and test data sets according to https://www.kaggle.com/c/titanic/data\n",
        "# But the test data of kaggle does not have labels\n",
        "# Therefore we will load  the whole data from a data repository then split it latter\n",
        "titanic_data = pd.read_csv(\"https://www.openml.org/data/get_csv/16826755/phpMYEkMl.csv\", na_values=['?']) #yo\n",
        "titanic_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO5p4beqrQtI"
      },
      "source": [
        "**Values considered “missing”**\n",
        "\n",
        "There are many ways to represent missing values in both the dataset file and the python pandas.\n",
        "\n",
        "Missing values in the data might be blank entries, or '?', or something else that data collecters agreed on to represent unobserved data.\n",
        "In this case it is '?' -- knowing this, we tell `pandas` what to consider as missing values via `na_values=['?']`.\n",
        "\n",
        "At the \"other end\", `pandas` can represent missing values in several different ways. As can be seen above, \"NaN\" is the default missing value marker, however, we need to be able to easily detect this value with data of different types: floating point, integer, boolean, and general object. In many cases, however, some other forms can refer to missing values such as None “missing” or “not available”, “NA\", or (-)inf .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZ-oRyNCCiQ_"
      },
      "outputs": [],
      "source": [
        "# Let's drop some features that we will not consider here.\n",
        "titanic_data.drop(['name','ticket', 'embarked', 'boat' ,'body' ,'home.dest'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG9OD8GJxoub"
      },
      "source": [
        "Now we will split the data to train and test subsets as **ONLY** the training data will be used to learn the imputers then the learnt models are applied to the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmiLsUmPyhZb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "y=titanic_data['survived']\n",
        "X=titanic_data.drop(['survived'], axis=1)\n",
        "X_titanic_train, X_titanic_test, y_titanic_train, y_titanic_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULBAEQU1P46k"
      },
      "outputs": [],
      "source": [
        "#Now if we perform classification it might not work for most classifiers\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier()\n",
        "#classifier=SVC()\n",
        "classifier.fit(X_titanic_train, y_titanic_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLzP_IAp2Gf7"
      },
      "source": [
        "# There is a problem that some features contain string values, namely the features \"sex\" and \"cabin\", so lets encode these features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WNskdjmNkEK"
      },
      "outputs": [],
      "source": [
        "# We need the upgraded sklearn to accept the parameters for encoders\n",
        "import sklearn\n",
        "!pip install -U scikit-learn\n",
        "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDv8Pdnf2oih"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Encoding categorical features with preserving the missing values in incomplete features\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "encoder_sex = OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value=np.nan)\n",
        "X_titanic_train_encoded=X_titanic_train.copy()\n",
        "X_titanic_train_encoded['sex'] = encoder_sex.fit_transform(X_titanic_train_encoded['sex'].values.reshape(-1, 1))\n",
        "\n",
        "#Now lets encode the incomplete Cabin feature\n",
        "encoder_cabin = OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value=np.nan) #You can use the same encoder for both but we use two for the sake of clarfication\n",
        "X_titanic_train_encoded['cabin'] = encoder_cabin.fit_transform(X_titanic_train_encoded['cabin'].values.reshape(-1, 1).astype(str))\n",
        "#get the code of the \"nan\" value for the cabin categorical feature\n",
        "cabin_nan_code=encoder_cabin.transform([['nan']])[0][0]\n",
        "print(cabin_nan_code)\n",
        "#Now, retrive the nan values to be missing in the encoded data\n",
        "X_titanic_train_encoded['cabin'].replace(cabin_nan_code,np.nan,inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iuJZIx3TSsH"
      },
      "source": [
        "## `X_titanic_train_encoded` is the encoded incomplete training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l1zGndjT6SF"
      },
      "outputs": [],
      "source": [
        "#Check the types of the encoded data, no object features\n",
        "X_titanic_train_encoded.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_titanic_train_encoded.head()"
      ],
      "metadata": {
        "id": "tAc-KVgFL2Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scikit-learn"
      ],
      "metadata": {
        "id": "KiIsKUCf6IS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1JaaXaVfOcx"
      },
      "outputs": [],
      "source": [
        "# As the data has no strings/object now, let's try performing classification using the encoded data\n",
        "classifier.fit(X_titanic_train_encoded, y_titanic_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVW4rvfcfpLz"
      },
      "source": [
        "## Note the error:ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
        "\n",
        "We need to handle the missing values before performing the classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0F3e1bGz_g9"
      },
      "source": [
        "Lets show the number of missing values in each feature of the encoded train data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7VBXC-BKtWP"
      },
      "outputs": [],
      "source": [
        "print(\"The number of missing values \")\n",
        "print(X_titanic_train_encoded.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ALzHzMNS20e"
      },
      "source": [
        "We have three incomplete features \"age\", \"fare\", and \"cabin\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRW0eosZ3ge5"
      },
      "source": [
        "## The deletion approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vvOVHp4KdrC"
      },
      "source": [
        "### Deleting the incomplete features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQ97hShDI7Vg"
      },
      "outputs": [],
      "source": [
        "X_titanic_train_complete=X_titanic_train_encoded.copy()\n",
        "X_titanic_train_complete.dropna(axis=1, inplace=True)\n",
        "X_titanic_train_complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RT6hNyCV4Go"
      },
      "outputs": [],
      "source": [
        "#Check the number of missing values\n",
        "print(X_titanic_train_complete.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lPQihJYKoZz"
      },
      "source": [
        "### Deleting the incomplete instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxWswJ3CKRYg"
      },
      "outputs": [],
      "source": [
        "X_titanic_train_complete=X_titanic_train_encoded.copy()\n",
        "X_titanic_train_complete.dropna(axis=0, inplace=True)\n",
        "#The difference is axis=0 instead of 1\n",
        "X_titanic_train_complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3MJRMFlWkFd"
      },
      "source": [
        "## Notice the reduction in the number of instances\n",
        "\n",
        "Another important point for the instance deletion approach is that there is a need to remove the target values (from y_train) that correspond to the incomplete (deleted) data instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uojOsx-xj_7h"
      },
      "outputs": [],
      "source": [
        "#Check the number of missing values\n",
        "print(X_titanic_train_complete.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqu5r4TjkRYw"
      },
      "source": [
        "The deletion approach has several drawbacks. It reduces the availlable data, which limits the learning ability, especially when there are many missing values.\n",
        "\n",
        "Furthermore, the approach of deleting incomplete instances is not practical for test data: we really want to know the answer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fej9EDBu4gwa"
      },
      "source": [
        "## Imputation using `pandas`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzmrmL0LLH2G"
      },
      "source": [
        "### Simple imputation (`pandas`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szCqnHFa9TOX"
      },
      "outputs": [],
      "source": [
        "#Mean for numeric values\n",
        "X_titanic_data_complete=X_titanic_train_encoded.copy()\n",
        "X_titanic_data_complete['age']=X_titanic_data_complete['age'].fillna(X_titanic_data_complete['age'].mean())\n",
        "X_titanic_data_complete['fare']=X_titanic_data_complete['fare'].fillna(X_titanic_data_complete['fare'].mean())\n",
        "X_titanic_data_complete['cabin']=X_titanic_data_complete['cabin'].fillna(X_titanic_data_complete['cabin'].mean())\n",
        "# Show the number of missing values\n",
        "print(X_titanic_data_complete.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVLK13FPmg5z"
      },
      "outputs": [],
      "source": [
        "X_titanic_data_complete.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgjetIE0YnNG"
      },
      "source": [
        "## \"interpolation\" (`pandas`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B42dnIO_AdF"
      },
      "outputs": [],
      "source": [
        "X_titanic_data_complete = X_titanic_train_encoded.copy()\n",
        "X_titanic_data_complete = X_titanic_data_complete.interpolate()\n",
        "#The output is 'numpy.ndarray' so we convert it to dataframe for consistency\n",
        "X_titanic_train_complete = pd.DataFrame(X_titanic_train_complete)\n",
        "print(X_titanic_train_complete.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGryHciLAWh8"
      },
      "source": [
        "## Imputation using `sklearn`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCvksIYCpMTJ"
      },
      "source": [
        "### Simple imputation (`sklearn`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3nH5WYSMKWT"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer()\n",
        "\n",
        "X_titanic_train_complete = imputer.fit_transform(X_titanic_train_encoded)\n",
        "\n",
        "#The output is 'numpy.ndarray' so we convert it to dataframe for consistency\n",
        "X_titanic_train_complete=pd.DataFrame(X_titanic_train_complete, columns=X_titanic_train_encoded.columns)\n",
        "print(\"The number of missing values :\\n\", X_titanic_train_complete.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2UUq_o1Ii0y"
      },
      "outputs": [],
      "source": [
        "X_titanic_train_encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0xJwIbkpkzN"
      },
      "source": [
        "## The default strategy for sklearn simple imputer is the \"mean\", you can change it using the strategy parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uESPaJdvpijl"
      },
      "outputs": [],
      "source": [
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "X_titanic_train_complete = imputer.fit_transform(X_titanic_train_encoded)\n",
        "#The output is 'numpy.ndarray' so we convert it to dataframe for consistency\n",
        "X_titanic_train_complete=pd.DataFrame(X_titanic_train_complete, columns=X_titanic_train_encoded.columns)\n",
        "print(\"The number of missing values :\\n\", X_titanic_train_complete.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_CxVEltuaDE"
      },
      "source": [
        "## kNN imputer (`sklearn`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UgUj_v8uQrG"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "imputer = KNNImputer()\n",
        "X_titanic_train_complete = imputer.fit_transform(X_titanic_train_encoded)\n",
        "#The output is 'numpy.ndarray' so we convert it to dataframe for consistency\n",
        "X_titanic_train_complete=pd.DataFrame(X_titanic_train_complete, columns=X_titanic_train_encoded.columns)\n",
        "print(\"The number of missing values :\\n\", X_titanic_train_complete.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5qXJ2sKwFsd"
      },
      "outputs": [],
      "source": [
        "#The default k for the KNN imputer is 5, you can change it as follows:\n",
        "imputer = KNNImputer(n_neighbors=2)\n",
        "# etc etc..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvjheXhSqGGS"
      },
      "source": [
        "## Iterative Imputer (`sklearn`)\n",
        "\n",
        "Note this is sklearn's implementation of a method originally known as \"MICE\" -- see lecture 2 from this week for an explanation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvAwiYugqFNh"
      },
      "outputs": [],
      "source": [
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "imputer = IterativeImputer()\n",
        "X_titanic_train_complete = imputer.fit_transform(X_titanic_train_encoded)\n",
        "#The output is 'numpy.ndarray' so we convert it to dataframe for consistency\n",
        "X_titanic_train_complete=pd.DataFrame(X_titanic_train_complete, columns=X_titanic_train_encoded.columns)\n",
        "print(\"The number of missing values :\\n\", X_titanic_train_complete.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQgAd4A7rAbb"
      },
      "source": [
        "You can reset the default parameters of the iterative imputer. For example, you can set the number of iterations. Moreover, you can specify the estimator for estimating the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9HyOV0ItAFI"
      },
      "outputs": [],
      "source": [
        "# Lets use DT as an estimator\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "imputer = IterativeImputer(estimator=DecisionTreeRegressor())\n",
        "X_titanic_train_complete = imputer.fit_transform(X_titanic_train_encoded)\n",
        "#The output is 'numpy.ndarray' so we convert it to dataframe for consistency\n",
        "X_titanic_train_complete=pd.DataFrame(X_titanic_train_complete, columns=X_titanic_train_encoded.columns)\n",
        "print(\"The number of missing values :\\n\", X_titanic_train_complete.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EZFmRdTxMkp"
      },
      "source": [
        "## Applying the learned models to incomplete test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVYvL9lWyhs0"
      },
      "source": [
        "First, apply the encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82vJ_pDLynfg"
      },
      "outputs": [],
      "source": [
        "#The learnt encoder_sex should be used to encode the test data, NOTE there is NO fit here, just transform\n",
        "X_titanic_test_encoded=X_titanic_test.copy()\n",
        "X_titanic_test_encoded['sex'] = encoder_sex.transform(X_titanic_test_encoded['sex'].values.reshape(-1, 1))\n",
        "\n",
        "#The learnt encoder2 should be used to encode the test data, NOTE there is NO fit here, just transform\n",
        "X_titanic_test_encoded['cabin'] = encoder_cabin.transform(X_titanic_test_encoded['cabin'].values.reshape(-1, 1).astype(str))\n",
        "#Now, retrive the nan values to be missing in the encoded data\n",
        "X_titanic_test_encoded['cabin'].replace(cabin_nan_code,np.nan,inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySdvd6bvyril"
      },
      "source": [
        "Second, use the learned imputer to estimate the missing values in the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFM_GJVvq00J"
      },
      "outputs": [],
      "source": [
        "print(\"The number of missing values in the test data before imputation :\\n\", X_titanic_test_encoded.isnull().sum())\n",
        "X_titanic_test_complete = imputer.transform(X_titanic_test_encoded)\n",
        "X_titanic_test_complete=pd.DataFrame(X_titanic_test_complete, columns=X_titanic_test_encoded.columns)\n",
        "print(\"The number of missing values in the test data after imputation :\\n\", X_titanic_test_complete.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv-xCT7czDnb"
      },
      "source": [
        "Finally, we can perform the classification using the imputed complete data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axtETBunwAXf"
      },
      "outputs": [],
      "source": [
        "#We use f-measure because the classes are not balanced\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(random_state=0)\n",
        "#classifier=SVC()\n",
        "classifier.fit(X_titanic_train_complete, y_titanic_train)\n",
        "print(\"F1 score after imputation = \", f1_score(classifier.predict(X_titanic_test_complete), y_titanic_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "QigdHhbuy5Zh"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}