{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Various Performance Metrics\n",
        "\n",
        "Here's what we will try out:\n",
        "## Classification\n",
        "   * Accuracy,\n",
        "   * Error rate,\n",
        "   * True Positive Rate,\n",
        "   * False Negative Rate,\n",
        "   * Specificity,\n",
        "   * Prcesion,\n",
        "   * Recall,\n",
        "   * F1-Measure,\n",
        "   * ROC Curve,\n",
        "   * AUC,\n",
        "   * Log Loss\n",
        "\n",
        "## Regression\n",
        "   * Mean Squared Error,\n",
        "   * Root Mean Squared Error,\n",
        "   * Relative Squared Error,\n",
        "   * Mean Absolute Error\n",
        "\n",
        "## Clustering\n",
        "   * Silhouette Score,\n",
        "   * Rand Index,\n",
        "   * Mutual Information"
      ],
      "metadata": {
        "id": "EOAWHJ6qS9Va"
      },
      "id": "EOAWHJ6qS9Va"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics for classification\n",
        "\n",
        "We'll use the [\"monks\" data](https://api.openml.org/d/334) - this is a totally made up toy dataset, but there are no missing values, so we can go straight to the prediction of the class."
      ],
      "metadata": {
        "id": "P4rOmmo2SBP4"
      },
      "id": "P4rOmmo2SBP4"
    },
    {
      "metadata": {
        "trusted": true,
        "id": "animal-cleanup"
      },
      "id": "animal-cleanup",
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "monks_data =pd.read_csv(\"https://www.openml.org/data/get_csv/52237/php4fATLZ.csv\")\n",
        "monks_data.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "formal-andrews"
      },
      "id": "formal-andrews",
      "cell_type": "markdown",
      "source": [
        "We split the data to \"train\" and \"test\" subsets. The learned models (trained on the \"train\" subset) will be applied to the test data."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "prompt-provider"
      },
      "id": "prompt-provider",
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "y=monks_data['class']\n",
        "X=monks_data.drop(['class'], axis=1)\n",
        "X_monks_train, X_monks_test, y_monks_train, y_monks_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "53a9efcd"
      },
      "id": "53a9efcd",
      "cell_type": "code",
      "source": [
        "X_monks_train.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_monks_train.tail()"
      ],
      "metadata": {
        "id": "JFVgHurdXESm"
      },
      "id": "JFVgHurdXESm",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "homeless-parameter"
      },
      "id": "homeless-parameter",
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score    # We use f1-measure because the classes are not balanced\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "\n",
        "# training data\n",
        "clf.fit(X_monks_train, y_monks_train)\n",
        "\n",
        "# testing data\n",
        "f1_score(clf.predict(X_monks_test), y_monks_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "extra-wesley"
      },
      "id": "extra-wesley",
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "#clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "#clf = GaussianNB()\n",
        "\n",
        "clf.fit(X_monks_train, y_monks_train)\n",
        "y_pred = clf.predict(X_monks_test)\n",
        "\n",
        "print(y_pred[:15])\n",
        "import numpy as np\n",
        "print(np.array(y_monks_test[:15]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = clf.predict_proba(X_monks_test)\n",
        "print(y_pred_prob[:5,:])"
      ],
      "metadata": {
        "id": "hM-pZMwXKKhw"
      },
      "id": "hM-pZMwXKKhw",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "prescription-fourth"
      },
      "id": "prescription-fourth",
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "expired-while"
      },
      "id": "expired-while",
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm=confusion_matrix(y_monks_test, y_pred)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "greatest-detail"
      },
      "id": "greatest-detail",
      "cell_type": "markdown",
      "source": [
        "### TP, FN, TN, FP"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "thousand-monthly"
      },
      "id": "thousand-monthly",
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = cm.ravel()\n",
        "print(\"TP = {}\".format(tp))\n",
        "print(\"FN = {}\".format(fn))\n",
        "print(\"TN = {}\".format(tn))\n",
        "print(\"FP = {}\".format(fp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dressed-positive"
      },
      "id": "dressed-positive",
      "cell_type": "markdown",
      "source": [
        "### We can calculate Accuracy, TPR, ... based on the confusion matrix first"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "included-adventure"
      },
      "id": "included-adventure",
      "cell_type": "code",
      "source": [
        "print(\"accuracy   = {}\".format((tp+tn)/(tn+fp+fn+tp)))\n",
        "print(\"TPR/Recall = {}\".format(tp/(tp+fn)))\n",
        "print(\"specificity= {}\".format(tn/(tn+fp)))\n",
        "print(\"Precision  = {}\".format(tp/(tp+fp)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "athletic-purple"
      },
      "id": "athletic-purple",
      "cell_type": "markdown",
      "source": [
        "### Use sklearn.metrics  "
      ]
    },
    {
      "metadata": {
        "id": "satisfactory-dinner"
      },
      "id": "satisfactory-dinner",
      "cell_type": "markdown",
      "source": [
        "### Accuracy"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "effective-equilibrium"
      },
      "id": "effective-equilibrium",
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_monks_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "warming-factory"
      },
      "id": "warming-factory",
      "cell_type": "markdown",
      "source": [
        "### Recall"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "single-wrestling"
      },
      "id": "single-wrestling",
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "r=recall_score(y_monks_test, y_pred)\n",
        "print(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gentle-holder"
      },
      "id": "gentle-holder",
      "cell_type": "markdown",
      "source": [
        "### Recall on the negative class == specificity"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "effective-tiger"
      },
      "id": "effective-tiger",
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "recall_score(y_monks_test, y_pred, pos_label=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "excellent-sailing"
      },
      "id": "excellent-sailing",
      "cell_type": "markdown",
      "source": [
        "### Precision"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "original-things"
      },
      "id": "original-things",
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "p=precision_score(y_monks_test, y_pred)\n",
        "print(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "metropolitan-string"
      },
      "id": "metropolitan-string",
      "cell_type": "markdown",
      "source": [
        "### F1-Measure"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "imported-maryland"
      },
      "id": "imported-maryland",
      "cell_type": "code",
      "source": [
        "print(\"directly: f1-score={}\".format(2*p*r/(p+r)))\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(y_monks_test, y_pred)\n",
        "\n",
        "print(\"sklearn : f1-score={}\".format(f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "divided-minister"
      },
      "id": "divided-minister",
      "cell_type": "markdown",
      "source": [
        "### ROC Curve and AUC"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "vital-format"
      },
      "id": "vital-format",
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "fpr, tpr, thresholds = roc_curve(y_monks_test, y_pred_prob[:,1], pos_label=1)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "#print(fpr)\n",
        "#print(tpr)\n",
        "#print(thresholds)\n",
        "print(\"The ROC AUC score = {}\".format(roc_auc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "instructional-archive"
      },
      "id": "instructional-archive",
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eleven-chester"
      },
      "id": "eleven-chester",
      "cell_type": "markdown",
      "source": [
        "### Log Loss"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "floating-anime"
      },
      "id": "floating-anime",
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "log_loss(y_monks_test, y_pred_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.exp(-0.36)\n"
      ],
      "metadata": {
        "id": "fEJlYAcBHOH4"
      },
      "id": "fEJlYAcBHOH4",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "considered-editor"
      },
      "id": "considered-editor",
      "cell_type": "markdown",
      "source": [
        "# Metrics for Regression\n",
        "\n",
        "For this, we use the Boston Housing data set, but check out the warning that sklearn throws up for this. Interesting!\n",
        "\n",
        " * the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html)\n",
        " * someone [digging](https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8)"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "confirmed-gospel"
      },
      "id": "confirmed-gospel",
      "cell_type": "code",
      "source": [
        "#from sklearn.datasets import load_boston\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#X, y = load_boston(return_X_y=True);\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get house information\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "houses = fetch_california_housing()\n",
        "\n",
        "X = houses.data\n",
        "y = houses.target\n",
        "\n",
        "df_data = pd.DataFrame(houses.data, columns=houses.feature_names)\n",
        "df_data.head()"
      ],
      "metadata": {
        "id": "0i_EenfI4CuY"
      },
      "id": "0i_EenfI4CuY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_houses_train, X_houses_test, y_houses_train, y_houses_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "XvSYbZ_K524a"
      },
      "id": "XvSYbZ_K524a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_houses_train"
      ],
      "metadata": {
        "id": "96Zq4AZZIANr"
      },
      "id": "96Zq4AZZIANr",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ongoing-brooklyn"
      },
      "id": "ongoing-brooklyn",
      "cell_type": "code",
      "source": [
        "#from sklearn.linear_model import LinearRegression\n",
        "from sklearn import ensemble\n",
        "\n",
        "params = {'n_estimators': 500,\n",
        "          'max_depth': 4,\n",
        "          'min_samples_split': 5,\n",
        "          'learning_rate': 0.01,\n",
        "          'loss': 'squared_error'}\n",
        "reg = ensemble.GradientBoostingRegressor(**params).fit(X_houses_train, y_houses_train)\n",
        "#reg = LinearRegression().fit(X_houses_train, y_houses_train)\n",
        "y_test_pred = reg.predict(X_houses_test)\n",
        "print(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "clinical-german"
      },
      "id": "clinical-german",
      "cell_type": "markdown",
      "source": [
        "### MSE"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "regular-auditor"
      },
      "id": "regular-auditor",
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(y_houses_test, y_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "liquid-torture"
      },
      "id": "liquid-torture",
      "cell_type": "markdown",
      "source": [
        "### R-Squared"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "flush-coalition"
      },
      "id": "flush-coalition",
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "print(r2_score(y_houses_test, y_test_pred))\n",
        "print(reg.score(X_houses_test, y_houses_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "refined-leonard"
      },
      "id": "refined-leonard",
      "cell_type": "markdown",
      "source": [
        "### MAE"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "right-dynamics"
      },
      "id": "right-dynamics",
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "mean_absolute_error(y_houses_test, y_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "passive-textbook"
      },
      "id": "passive-textbook",
      "cell_type": "markdown",
      "source": [
        "#  Performance Metrics - Clustering\n",
        "\n",
        "NOTE: it would be much better to compare k-means here with a second clustering algorithm! The following just indicates how to call silhouette (and others).\n",
        "I do compare different k at the end, but a second clusterer would be good.\n",
        "\n",
        "Examples here:\n",
        " * silhouette\n",
        " * Rand (named after Rand, not \"random\"!)\n",
        " * mutual information"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "surprising-assumption"
      },
      "id": "surprising-assumption",
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=2, random_state=0, n_init='auto').fit(X_houses_train)\n",
        "kmeans_train_labels = kmeans.labels_\n",
        "kmeans_test_labels  = kmeans.predict(X_houses_test)\n",
        "print(kmeans_train_labels[:10])\n",
        "type(kmeans_train_labels[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "HjStKGUGFoDq"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "# do it for train and test sets\n",
        "score_train = silhouette_score(X_houses_train, kmeans_train_labels, metric='euclidean')\n",
        "score_test  = silhouette_score(X_houses_test,  kmeans_test_labels,  metric='euclidean')\n",
        "print(\"Silhouette on train: {0:6.2f} \\t test: {1:6.2f} \".format(score_train, score_test))"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "HjStKGUGFoDq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we look at the silhouette score for k-means as we increase k"
      ],
      "metadata": {
        "id": "mFRiIuCBB8yd"
      },
      "id": "mFRiIuCBB8yd"
    },
    {
      "cell_type": "code",
      "source": [
        "for k in [2,3,4,6,10,20, 30]:\n",
        "  kmeans = KMeans(n_clusters=k, random_state=0, n_init='auto').fit(X_houses_train)\n",
        "  kmeans_train_labels = kmeans.labels_\n",
        "  kmeans_test_labels  = kmeans.predict(X_houses_test)\n",
        "  sil_train = silhouette_score(X_houses_train, kmeans_train_labels, metric='euclidean')\n",
        "  sil_test  = silhouette_score(X_houses_test, kmeans_test_labels, metric='euclidean')\n",
        "  print(\"k={0:3d} \\t Silhouette on train: {1:6.2f} \\t test: {2:6.2f} \".format(k, sil_train, sil_test))"
      ],
      "metadata": {
        "id": "Nx0bPHfa73hc"
      },
      "id": "Nx0bPHfa73hc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying a couple of alternative metrics for clustering"
      ],
      "metadata": {
        "id": "BEaguhPrFPCV"
      },
      "id": "BEaguhPrFPCV"
    },
    {
      "metadata": {
        "trusted": true,
        "id": "warming-playback"
      },
      "id": "warming-playback",
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import rand_score\n",
        "# do it for train and test sets\n",
        "score_train = rand_score(y_houses_train, kmeans_train_labels)\n",
        "score_test  = rand_score(y_houses_test,  kmeans_test_labels)\n",
        "print(\"Rand on train: {0:6.2f} \\t test: {1:6.2f} \".format(score_train, score_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "neutral-yemen"
      },
      "id": "neutral-yemen",
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mutual_info_score\n",
        "score_train = mutual_info_score(y_houses_train, kmeans_train_labels)\n",
        "score_test  = mutual_info_score(y_houses_test,  kmeans_test_labels)\n",
        "print(\"Mutual Information on train: {0:6.2f} \\t test: {1:6.2f} \".format(score_train, score_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N0ki5h2r8qI7"
      },
      "id": "N0ki5h2r8qI7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "athletic-purple"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}